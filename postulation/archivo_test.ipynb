{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 1: Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 15:30:46.314222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-08 15:30:46.682730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-08 15:30:46.682752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-03-08 15:30:46.727334: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 15:30:47.670105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-08 15:30:47.670204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-08 15:30:47.670211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Celda para probar importaciones (ejecuta esta primero)\n",
    "try:\n",
    "    from docx import Document\n",
    "    from docx2pdf import convert\n",
    "    from transformers import pipeline\n",
    "    import torch\n",
    "    import sentencepiece\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    print(\"✅ Librerías importadas correctamente.\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ Error al importar librerías:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /root/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages (from python-docx) (4.9.1)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, python-docx\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed python-docx-1.1.2 typing-extensions-4.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting docx2pdf\n",
      "  Downloading docx2pdf-0.1.8-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /root/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages (from docx2pdf) (4.64.1)\n",
      "Downloading docx2pdf-0.1.8-py3-none-any.whl (6.7 kB)\n",
      "Installing collected packages: docx2pdf\n",
      "Successfully installed docx2pdf-0.1.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n",
    "!pip install docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# huggingface-cli login --token mi_token  # Para autenticar el token en la terminal\n",
    "# make reuqes acces in  https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en caso de tener problemas con las versioone de los transformers\n",
    "# pip install --upgrade transformers tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Celda 2: Inicialización del Modelo LLM (Hugging Face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ba7c350fe44ac99717420358ca8b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Test simple del modelo Mistral desde HuggingFace\n",
    "try:\n",
    "    generador = pipeline(\"text-generation\",\n",
    "                         model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "                         device=\"cpu\")\n",
    "    \n",
    "    print(\"✅ Modelo cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error al cargar el modelo:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Celda 3: Test simple generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/.pyenv/versions/Artefact/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔖 Texto generado por IA:\n",
      "Ecris une courte phrase de motivation pour postuler en tant que Data Analyst.\n",
      "\n",
      "I am excited to apply for the Data Analyst position and bring my strong analytical skills, proficiency in data visualization tools, and passion for uncovering insights from data to your team. I am confident that my ability to work\n"
     ]
    }
   ],
   "source": [
    "# Probamos generación de texto sencillo\n",
    "prompt_test = \"Ecris une courte phrase de motivation pour postuler en tant que Data Analyst.\"\n",
    "\n",
    "resultado_test = generador(prompt_test, max_new_tokens=50, temperature=0.7)\n",
    "texto_generado = resultado_test[0][\"generated_text\"]\n",
    "\n",
    "print(\"🔖 Texto generado por IA:\")\n",
    "print(texto_generado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Celda 4: Test de creación de archivo Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo Word creado correctamente en /mnt/c/aa_aa_postulacion/lettres_motivation/\n"
     ]
    }
   ],
   "source": [
    "# Prueba creación archivo Word\n",
    "ruta_guardado = r\"/mnt/c/aa_aa_postulacion/lettres_motivation/\"\n",
    "nombre_test = \"test_archivo_word.docx\"\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(ruta_guardado, exist_ok=True)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_paragraph(\"Ceci est un test pour vérifier la création du fichier Word.\")\n",
    "doc.save(os.path.join(ruta_guardado, nombre_test))\n",
    "\n",
    "if os.path.exists(os.path.join(ruta_guardado, nombre_test)):\n",
    "    print(f\"✅ Archivo Word creado correctamente en {ruta_guardado}\")\n",
    "else:\n",
    "    print(\"❌ Error al crear el archivo Word.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalar \n",
    "# sudo apt update\n",
    "# sudo apt install libreoffice -y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Celda 5: Conversión de archivo .docx a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "docx2pdf is not implemented for linux as it requires Microsoft Word to be installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m archivo_word \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ruta_guardado, nombre_test)\n\u001b[1;32m      3\u001b[0m archivo_pdf \u001b[38;5;241m=\u001b[39m archivo_word\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchivo_word\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(archivo_pdf):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Archivo convertido correctamente a PDF en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchivo_pdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/Artefact/lib/python3.10/site-packages/docx2pdf/__init__.py:108\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(input_path, output_path, keep_active)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m windows(paths, keep_active)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocx2pdf is not implemented for linux as it requires Microsoft Word to be installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: docx2pdf is not implemented for linux as it requires Microsoft Word to be installed"
     ]
    }
   ],
   "source": [
    "# Prueba conversión directa a PDF( nofunciona mas que en linux)\n",
    "archivo_word = os.path.join(ruta_guardado, nombre_test)\n",
    "archivo_pdf = archivo_word.replace(\".docx\", \".pdf\")\n",
    "\n",
    "convert(archivo_word)\n",
    "\n",
    "if os.path.exists(archivo_pdf):\n",
    "    print(f\"✅ Archivo convertido correctamente a PDF en {archivo_pdf}\")\n",
    "else:\n",
    "    print(\"❌ Error en la conversión a PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /mnt/c/aa_aa_postulacion/lettres_motivation/test_archivo_word.docx as a Writer document -> /mnt/c/aa_aa_postulacion/lettres_motivation/test_archivo_word.pdf using filter : writer_pdf_Export\n",
      "✅ Archivo PDF creado correctamente: /mnt/c/aa_aa_postulacion/lettres_motivation/test_archivo_word.pdf\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from docx import Document\n",
    "\n",
    "# Ruta en WSL (que corresponde a Windows)\n",
    "ruta_guardado = \"/mnt/c/aa_aa_postulacion/lettres_motivation\"\n",
    "nombre_archivo = \"test_archivo_word.docx\"\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(ruta_guardado, exist_ok=True)\n",
    "\n",
    "# Crear un archivo DOCX de prueba\n",
    "doc = Document()\n",
    "doc.add_paragraph(\"Ceci est un test WSL pour vérifier la création du fichier Word.\")\n",
    "ruta_docx = os.path.join(ruta_guardado, nombre_test)\n",
    "doc.save(ruta_docx)\n",
    "\n",
    "# Ahora convertir directamente a PDF usando libreoffice en WSL\n",
    "try:\n",
    "    subprocess.run([\n",
    "        \"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", ruta_docx, \"--outdir\", ruta_guardado\n",
    "    ], check=True)\n",
    "\n",
    "    ruta_pdf = ruta_docx.replace(\".docx\", \".pdf\")\n",
    "    if os.path.exists(ruta_docx.replace(\".docx\", \".pdf\")):\n",
    "        print(f\"✅ Archivo PDF creado correctamente: {ruta_docx.replace('.docx', '.pdf')}\")\n",
    "    else:\n",
    "        print(\"❌ Error al convertir archivo a PDF con LibreOffice.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al ejecutar LibreOffice: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing code api hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Token de acceso de Hugging Face (colócalo aquí)\n",
    "HUGGING_FACE_TOKEN = \"__________\"\n",
    "\n",
    "# URL de la API\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔖 Texto generado por IA:\n",
      " Cuál es el origen de los idiomas?\n",
      "\n",
      "The origin of languages is a complex and multifaceted question that has been studied by linguists, anthropologists, and other scholars for many years. The prevailing theory among most linguists is that all human languages descend from a common ancestor language, known as Proto-World or Proto-Human language. This common ancestor language is believed to have been spoken by early hominids around 50,000 to 100,000 years ago.\n",
      "\n",
      "The exact origins of any specific language, however, are much more difficult to determine. Languages evolve over time through a process of change called language change. This can include the development of new sounds, the creation of new words, the shift in meaning of existing words, and the formation of new grammatical structures. As languages change, they become distinct from one another, making it difficult to trace their origins back to a common ancestor.\n",
      "\n",
      "Some\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Headers con el token de autenticación\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HUGGING_FACE_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "#prompt \n",
    "prompt = \" Cuál es el origen de los idiomas?\"\n",
    "# Leer el contenido del prompt desde el archivo\n",
    "#with open(\"prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "#    prompt = file.read()\n",
    "\n",
    "# Datos para la solicitud\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"temperature\": 0.7 # \n",
    "    }\n",
    "}\n",
    "\n",
    "# Enviar la solicitud a la API\n",
    "try:\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Lanza un error si la respuesta no es 200\n",
    "    resultado = response.json()\n",
    "\n",
    "    # Extraer el texto generado\n",
    "    texto_generado = resultado[0][\"generated_text\"]\n",
    "    \n",
    "    print(\"🔖 Texto generado por IA:\")\n",
    "    print(texto_generado)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"❌ Error al hacer la solicitud:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Artefact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
